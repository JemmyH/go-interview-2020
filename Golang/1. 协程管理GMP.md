# 一、概述

## 0. 前言

现在主流的线程模型分三种：内核级线程模型、用户级线程模型和两级线程模型（也称混合型线程模型），传统的协程库属于**用户级线程模型**，而 goroutine 和它的 `Go Scheduler` 在底层实现上其实是属于**两级线程模型**，因此，有时候为了方便理解可以简单把 goroutine 类比成协程，但心里一定要有个清晰的认知 — goroutine 并不等同于协程。

线程的实现模型主要有 3 种：内核级线程模型、用户级线程模型和两级线程模型（也称混合型线程模型），它们之间最大的差异就在于用户线程与内核调度实体（KSE，Kernel Scheduling Entity）之间的对应关系上。而所谓的内核调度实体 KSE 就是指可以被操作系统内核调度器调度的对象实体（这说的啥玩意儿，敢不敢通俗易懂一点？）。简单来说 KSE 就是内核级线程，是操作系统内核的最小调度单元，也就是我们写代码的时候通俗理解上的线程了。

**用户级线程模型**
用户线程与内核线程 KSE 是多对一（N : 1）的映射模型，多个用户线程的一般从属于单个进程并且多线程的调度是由用户自己的线程库来完成，线程的创建、销毁以及多线程之间的协调等操作都是由用户自己的线程库来负责而无须借助系统调用来实现。一个进程中所有创建的线程都只和同一个 KSE 在运行时动态绑定，也就是说，操作系统只知道用户进程而对其中的线程是无感知的，内核的所有调度都是基于用户进程。许多语言实现的 协程库 基本上都属于这种方式（比如 python 的 gevent）。由于线程调度是在用户层面完成的，也就是相较于内核调度不需要让 CPU 在用户态和内核态之间切换，这种实现方式相比内核级线程可以做的很轻量级，对系统资源的消耗会小很多，因此可以创建的线程数量与上下文切换所花费的代价也会小得多。但该模型有个原罪：并不能做到真正意义上的并发，假设在某个用户进程上的某个用户线程因为一个阻塞调用（比如 I/O 阻塞）而被 CPU 给中断（抢占式调度）了，那么该进程内的所有线程都被阻塞（因为单个用户进程内的线程自调度是没有 CPU 时钟中断的，从而没有轮转调度），整个进程被挂起。即便是多 CPU 的机器，也无济于事，因为在用户级线程模型下，一个 CPU 关联运行的是整个用户进程，进程内的子线程绑定到 CPU 执行是由用户进程调度的，内部线程对 CPU 是不可见的，此时可以理解为 CPU 的调度单位是用户进程。所以很多的协程库会把自己一些阻塞的操作重新封装为完全的非阻塞形式，然后在以前要阻塞的点上，主动让出自己，并通过某种方式通知或唤醒其他待执行的用户线程在该 KSE 上运行，从而避免了内核调度器由于 KSE 阻塞而做上下文切换，这样整个进程也不会被阻塞了。

**内核级线程模型**
用户线程与内核线程 KSE 是一对一（1 : 1）的映射模型，也就是每一个用户线程绑定一个实际的内核线程，而线程的调度则完全交付给操作系统内核去做，应用程序对线程的创建、终止以及同步都基于内核提供的系统调用来完成，大部分编程语言的线程库(比如 Java 的 java.lang.Thread、C++11 的 std::thread 等等)都是对操作系统的线程（内核级线程）的一层封装，创建出来的每个线程与一个独立的 KSE 静态绑定，因此其调度完全由操作系统内核调度器去做，也就是说，一个进程里创建出来的多个线程每一个都绑定一个 KSE。这种模型的优势和劣势同样明显：优势是实现简单，直接借助操作系统内核的线程以及调度器，所以 CPU 可以快速切换调度线程，于是多个线程可以同时运行，因此相较于用户级线程模型它真正做到了并行处理；但它的劣势是，由于直接借助了操作系统内核来创建、销毁和以及多个线程之间的上下文切换和调度，因此资源成本大幅上涨，且对性能影响很大。

**两级线程模型**
两级线程模型是博采众长之后的产物，充分吸收前两种线程模型的优点且尽量规避它们的缺点。在此模型下，用户线程与内核 KSE 是多对多（N : M）的映射模型：首先，区别于用户级线程模型，两级线程模型中的一个进程可以与多个内核线程 KSE 关联，也就是说一个进程内的多个线程可以分别绑定一个自己的 KSE，这点和内核级线程模型相似；其次，又区别于内核级线程模型，它的进程里的线程并不与 KSE 唯一绑定，而是可以多个用户线程映射到同一个 KSE，当某个 KSE 因为其绑定的线程的阻塞操作被内核调度出 CPU 时，其关联的进程中其余用户线程可以重新与其他 KSE 绑定运行。所以，两级线程模型既不是用户级线程模型那种完全靠自己调度的也不是内核级线程模型完全靠操作系统调度的，而是中间态（自身调度与系统调度协同工作），也就是 — 『薛定谔的模型』（误），因为这种模型的高度复杂性，操作系统内核开发者一般不会使用，所以更多时候是作为第三方库的形式出现，而 Go 语言中的 runtime 调度器就是采用的这种实现方案，实现了 Goroutine 与 KSE 之间的动态关联，不过 Go 语言的实现更加高级和优雅；该模型为何被称为两级？即用户调度器实现用户线程到 KSE 的『调度』，内核调度器实现 KSE 到 CPU 上的『调度』。

## 1. 为什么在内核的线程调度器之外，Go还需要实现一个自己的调度器？

主要解决**系统线程太重**的问题：

1.  创建与切换线程 太重：都需要在用户态和内核态之间切换，开销较大；
2.  系统线程内存使用 太重：一方面，创建系统线程时会分配一段大部分情况下都用不完的栈内存，造成浪费；另一方面，栈内存空间创建后其大小不会再变化，有溢出的风险。

goroutine是Go语言实现的用户态的线程，可以看做是对系统线程进行的一层抽象。有了这层抽象，Golang程序员不会直接面对系统线程，直接使用goroutine就可以了，而操作系统不会care什么goroutine，只是执行设定好的系统线程就好了。这层抽象，就是Go的调度器，后面会详细说明。Go很精巧地解决了上述两个问题：

1.  goroutine是用户态线程，其创建和切换等，都是在用户态完成而无需进入操作系统内核，其开销相比系统线程要小很多；
2.  goroutine启动时默认栈大小只有2k，可以根据实际情况进行自动伸缩。

## 2. Go scheduler

Go程序的执行由两部分组成：`Go Program` 和 `runtime`，即 `用户代码` 和 `运行时`。这里的runtime和Java、Python中的不一样，Java的是虚拟机，而**Go的runtime和用户代码一起编译到一个可执行文件中**。用户代码和runtime除了代码组织上有界限之外，运行的时候并没有明显的界限，**用户代码中，一些常用的关键字(如go, new等)被编译成runtime包下的一些函数调用**。**用户程序进行的系统调用都会被runtime拦截**，以此来帮助runtime进行调度方面以及垃圾回收其他方面的工作。

一张关系图如下：

![用户代码和runtime的关系](https://pic.downk.cc/item/5f5f3897160a154a67e17110.png)

为什么需要scheduler呢？runtime维护所有的goroutine，就是通过scheduler来进行调度。goroutine和系统线程是独立的，但是goroutine需要依赖系统线程才能执行。

可以用一句话概括Go scheduler的目标：

>   For scheduling goroutines onto kernel threads.

Go scheduler的核心思想是：

1.  reuser 系统线程，限制同时运行(不包括阻塞的)的线程数为N，其中N为CPU的核心数；
2.  线程使用私有的本地运行队列，并且为了更高地使用CPU，某个线程可以从其他线程偷goroutine来帮助运行，也可以在goroutine阻塞的时候将其传递给其他线程。

## 3. M:N模型

goroutine建立在操作系统线程之上，它与操作系统线程之间实现了一个多对多(M:N)的两级线程模型。M:N是指M的goroutine运行在N的操作系统线程上，内核负责对这N的操作系统线程进行调度，而Go runtime则负责将这M个goroutine调度运用在这N个操作系统线程上。

简单理解，对goroutine的调度，是指程序代码按照一定的算法，在适当的时候挑选出合适的goroutine然后放到真正的线程上去执行的过程。其实**并没有一个调度器实体，它只是一段代码的抽象化表示**，具体来说是 需要发生调度时由操作系统线程执行`runtime.schedule`方法进行的。

Go runtime负责goroutine的生老病死，从创建、切换、销毁都一手包办。runtime在启动的时候，会创建M个操作系统线程(CPU内核执行调度的基本单位)，之后创建的N个goroutine都会依附在这M个线程上执行。在同一时刻，一个系统线程上只能执行一个goroutine，当goroutine发生阻塞时，runtime会将当前goroutine调走，让其他的goroutine继续执行。这样做的目的是尽量提升性能，尽量让所有的系统线程上面都有代码在执行。

## 4. GPM模型

我们观察调度过程的进化，从进程到线程再到协程，其实是一个不断共享、不断**减少切换成本**的过程。

要理解调度，需要理解两个概念：**运行**和**阻塞**。这里提供两个角度：我们觉得自己就是线程或者协程，运行就是在低头不断做事，阻塞就是我们目前做的事需要等待别人，然后就一直等着，等其他人做完了，我们接着做，这里我们是站在线程或者协程的角度去看的；另一个角度是，我们站在CPU的角度看，我正在敲代码写需求(一个线程或者协程)，发现依赖别人的函数还没有提交，那就把敲代码这事放在一边，最小化IDE然后点开钉钉沟通下一个需求，等依赖的函数提交了，又打开IDE继续敲代码——在Linux中，线程对应的是一个叫做`task_struct`的结构体，从本质上来说，线程并不是一个实体，**线程只是代表一个执行流和其状态**。真正驱动流程的是CPU，CPU根据 PC 寄存器从程序中取指令和操作数，从 RAM 中取数据,，进行计算、 处理、 跳转、 驱动执行流往前。 CPU 并不关注处理的是线程还是协程,，只需要设置 PC 寄存器， 设置栈指针等(这些称为上下文),，那么 CPU 就可以运行这个线程或者协程了。

所以，线程的运行，其实是被运行；线程的阻塞，其实是换出调度队列，不再去执行这个执行流。协程同理，协程也是一个类似于`task_struct`数据结构，其作用也是一个执行流或者状态，记录运行什么函数，运行到什么程度，也就是上下文。

Go在用户态实现调度，所以Go也需要有代表协程这种执行体的数据结构，也要有保存和恢复上下文的处理过程以及调度队列。

在这些数据结果中，最主要的是一下几个(以下结构体均位于`runtime`包的`runtime.go`文件中)：

-   `g`: 它保存了goroutine的所有信息，该结构体的每一个实例对象都代表了一个**goroutine**。调度器代码会通过g对象来对goroutine进行调度——当goroutine被调离系统线程时，调度器负责把CPU相关寄存器值等上下文信息保存在g对象的成员变量中；当goroutine被重新拉起运行时，调度器又负责把g对象成员变量中所保存的上下文信息恢复到相关寄存器，也就是恢复了执行上下文。
-   `schedt`：一方面保存调度器本身的状态信息，另一方面它拥有一个用来保存goroutine的运行队列。因为每个Go程序只有一个调度器，所以在每个Go程序中schedt结构体只有一个实例对象，该实例对象在源代码中被定义成了一个共享的全局变量，这样每个工作线程都可以访问它以及它所拥有的goroutine运行队列，我们称这个运行队列为**全局运行队列(GRQ)**。
-   `p`：表示执行所需要的资源，其最大数量同时也是Go代码的最大并行度。每一个运行着go代码的工作线程都会与一个p结构体的实例对象关联在一起。全局运行队列是每一个工作线程都可以读写的，因此为了并发安全，访问时需要加锁，但加锁势必耗费性能进而称为瓶颈。于是调度器为每一个工作线程引入了一个 **私有的goroutine运行队列**，我们称之为“**局部队列(LRQ)**”，工作线程优先使用局部队列的goroutine，只有必要时才会去访问全局队列(后面还会了解到，当一个p的局部队列使用完时，还会去别的p偷几个g过来运行)，这大大减少了锁冲突，提高了工作线程的并发性。
-   `m`：代表实际工作线程，每一个**工作线程**都有唯一的`m`与之对应。m结构体对象除了记录着工作线程的诸如栈的起止位置、当前正在执行的goroutine以及是否空闲等等状态信息之外，还通过指针维持着与p结构体的实例对象之间的绑定关系。于是，通过m既可以找到与之对应的工作线程正在运行的goroutine，又可以找到工作线程的局部运行队列等资源。

他们之间的关系，可以使用下图表示：

![GPM关系](https://pic.downk.cc/item/5f5f38b3160a154a67e1771f.png)

另有一张图可能更清晰形象：

![GPM关系](https://pic.downk.cc/item/5f5f38c0160a154a67e179c8.jpg)

Go scheduler 的职责就是将所有处于 可运行状态 的 goroutines 均匀分布到在 P 上运行的 M。

当一个 P 发现自己的 LRQ 已经没有 G 时，会从其他 P “偷” 一些 G 来运行。这被称为 `Work-stealing`，Go 从 1.1 开始实现。

Go scheduler 使用 M:N 模型，在任一时刻，M 个 goroutines（G） 要分配到 N 个内核线程（M），这些 M 跑在个数最多为 GOMAXPROCS 的逻辑处理器（P）上。每个 M 必须依附于一个 P，每个 P 在同一时刻只能运行一个 M。如果 P 上的 M 阻塞了，那它就需要其他的 M 来运行 P 的 LRQ 里的 goroutines。

实际上，Go scheduler 每一轮调度要做的工作就是找到处于 runnable 的 goroutines，并执行它。寻找的顺序如下：

```go
runtime.schedule() {
    // 检查全局队列，防止全局队列中的G被饿死
    // if not found, 检查局部队列
    // if not found, 
    // 		尝试从其他的P偷一些G过来
    // 		if not found, 从全局队列中去一些
    //      if not found, poll network
}
```

上述任何一步找到一个可执行的 goroutine 后，就会一直执行下去，直到被阻塞。当 P2 上的一个 G 执行结束，它就会去 LRQ 获取下一个 G 来执行。如果 LRQ 已经空了，就是说本地可运行队列已经没有 G 需要执行，并且这时 GRQ 也没有 G 了。这时，P2 会随机选择一个 P（称为 P1），P2 会从 P1 的 LRQ “偷”过来**一半**的 G。

这样做的好处是，有更多的 P 可以一起工作，加速执行完所有的 G。

## 5. goroutine的状态

如下图：

![goroutine状态转移](https://pic.downk.cc/item/5f5f38d1160a154a67e17e44.jpg)

## 6. Go  scheduler的调度时机

在以下四种情况下，scheduler可能会发生调度——“可能”意味着，scheduler只是有机会调度，但并不一定会发生。

|      情形       | 说明                                                         |
| :-------------: | :----------------------------------------------------------- |
| 使用关键字 `go` | 创建一个新的goroutine，scheduler会考虑调度                   |
|       GC        | 肯定会发生调度，因为GC必须要在M上运行。                      |
|  发生系统调用   | 当一个goroutine发生系统调用时，会阻塞M，此时它会被调走，同时调用新的goroutine在M上运行 |
|  内存同步访问   | atomic，mutex，channel 操作等会使 goroutine 阻塞，因此会被调度走。等条件满足后（例如其他 goroutine 解锁了）还会被调度上来继续运行 |

## 7. 同步/异步系统调用概览

当一个正在执行的G(goroutine)需要进行系统调用时，根据调用类型，它所依附的M有两种情况：**同步(系统调用等)** 和 **异步(网络请求等)**。

![同步系统调用](https://pic.downk.cc/item/5f5f38ec160a154a67e18425.jpg)

>   **同步**情况下，M1会被阻塞，进而从P上调度下来，此时G1依然依附在M1上执行，之后会有一个新的M2被调用到P上，接着执行P的本地运行队列LRQ中的G。一旦系统调用完成，G1会再次加入P的LRQ等待被调度，而之前的M1则会被隐藏，等到需要的时候再次被使用。

![异步系统调用](https://pic.downk.cc/item/5f5f3904160a154a67e18d56.jpg)

>   **异步**情况下，M1不会被阻塞，G1的异步请求会被另一个组件`Network Poller`接手，而G1本身也会被绑定到`Network Poller`上，等到系统调用结束，G1会再次回到P上。由于M没有被阻塞，它可以继续执行当前被绑定的P的LRQ里面的G。
>
>   可以看到，在异步情况下，通过调度，Go scheduler成功地将IO任务转变成了CPU任务，或者说将内核级别的线程切换转变成了用户级别的goroutine切换，极大地提高了效率。

# 二、具体实现

有时间再细究。

未完，待续…



## 参考

-   [https://strikefreedom.top/high-performance-implementation-of-goroutine-pool](https://strikefreedom.top/high-performance-implementation-of-goroutine-pool)